# Medical Visual Question Answering: A Multimodal Approach Leveraging Temporal Information
Healthcare data is inherently multimodal, comprising textual (e.g., clinical notes, radiology reports), visual (e.g., radiological scans, digitized histopathology slides), and structured (e.g., vital signs, laboratory results) components. In clinical practice, healthcare professionals synthesize information from these diverse sources to deliver comprehensive patient care, necessitating AI/ML models capable of processing heterogeneous data inputs.

Recent advances in Vision Language Models (VLMs) have demonstrated the ability to integrate visual and textual information for healthcare applications. These models have been successfully applied to tasks such as medical image classification, disease diagnosis, and automated report generation. Some studies have also explored the use of VLMs for medical visual question answering (VQA), where models interpret medical images and associated text to answer clinically relevant questions.

However, most current approaches treat each image-report pair independently, overlooking the temporal aspects of medical data. To address this limitation, some studies have incorporated longitudinal data for tasks like report generation, progression modeling, and disease classification. Yet, these approaches often neglect the rich information in Electronic Health Record (EHR) tabular data, which offers daily insights into patient conditions. Moreover, to our knowledge, few studies have explored using longitudinal data for medical Visual Question Answering (VQA) tasks, which are crucial for mimicking real-world clinical scenarios.

Building upon these advances, we propose a novel approach that leverages the inherent temporal structure in medical data, including EHR tabular data, for medical VQA tasks. Our method incorporates prior images, reports, and structured EHR data in the analysis, better reflecting the reality of clinical decision-making. By exploiting temporal correlations, we aim to provide a more comprehensive understanding of patient trajectories and disease progression. Consequently, our approach aims to improve the accuracy and clinical relevance of medical Visual Question Answering by incorporating longitudinal data and EHR information, potentially enabling enhanced patient monitoring in real-world clinical scenarios.
